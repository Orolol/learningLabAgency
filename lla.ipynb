{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/orolol\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('workspace/learningLabAgency/data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, transformer_model_name, num_labels):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(transformer_model_name)\n",
    "        self.classifier = nn.Linear(self.transformer.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs[0][:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "model_name = \"bert-base-uncased\" \n",
    "num_labels = 7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_embed = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Define the device\n",
    "\n",
    "\n",
    "class EssayDataset(Dataset):\n",
    "    \n",
    "        def __init__(self, df, tokenizer, model):\n",
    "            self.df = df\n",
    "            self.tokenizer = tokenizer\n",
    "            self.model = model\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            text = self.df['full_text'][idx]\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "    \n",
    "            if len(tokens) > 512:\n",
    "                tokens = tokens[:512]\n",
    "                \n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            \n",
    "            if len(token_ids) < 512:\n",
    "                token_ids += [0] * (512 - len(token_ids))\n",
    "\n",
    "            attention_mask = [1 if token_id != 0 else 0 for token_id in token_ids]\n",
    "            input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)  \n",
    "            attention_mask = torch.tensor(attention_mask).unsqueeze(0).to(device)  \n",
    "    \n",
    "            return input_ids, self.df['score'][idx], attention_mask\n",
    "        \n",
    "dataset = EssayDataset(df, tokenizer, model_embed)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "model = TransformerClassifier(model_name, num_labels).to(device)  \n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strat training\n",
      "[2 2 2 3 5 4 2 2]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20349/729745239.py:16: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = 1 - (np.sum(weight_matrix * o) / np.sum(weight_matrix * expected))\n",
      "/home/orolol/.pyenv/versions/3.12.0/envs/orolol/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1 loss: 8.65086841583252 mean : 0 kappa nan\n",
      "[2 2 4 4 5 4 3 2]\n",
      "[[2]\n",
      " [3]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [2]\n",
      " [3]\n",
      " [0]]\n",
      "Epoch 1, Batch 2 loss: 3.1422946453094482 mean : 0 kappa nan\n",
      "[3 3 3 3 2 3 1 1]\n",
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "Epoch 1, Batch 3 loss: 0.7344210147857666 mean : 0 kappa nan\n",
      "[2 3 3 3 2 3 4 4]\n",
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "Epoch 1, Batch 4 loss: 1.9284213781356812 mean : 0 kappa nan\n",
      "[3 2 6 2 3 3 2 3]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Epoch 1, Batch 5 loss: 52.22657012939453 mean : 0 kappa nan\n",
      "[4 5 3 4 3 4 4 2]\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m outputs_rounded \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mround()\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     51\u001b[0m outputs_rounded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(outputs_rounded, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m kappa \u001b[38;5;241m=\u001b[39m \u001b[43mquadratic_weighted_kappa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_rounded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     54\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mquadratic_weighted_kappa\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquadratic_weighted_kappa\u001b[39m(y_true, y_pred):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Calculates the Quadratic Weighted Kappa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    y_true: array, true labels\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    y_pred: array, predicted labels\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     n \u001b[38;5;241m=\u001b[39m o\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      9\u001b[0m     row_sums \u001b[38;5;241m=\u001b[39m o\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m     25\u001b[0m max_rating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(y_true), \u001b[38;5;28mmax\u001b[39m(y_pred)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 26\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_rating\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rating\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(y_true, y_pred):\n\u001b[1;32m     28\u001b[0m     matrix[t, p] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Quadratic Weighted Kappa\n",
    "    y_true: array, true labels\n",
    "    y_pred: array, predicted labels\n",
    "    \"\"\"\n",
    "    o = confusion_matrix(y_true, y_pred)\n",
    "    n = o.sum()\n",
    "    row_sums = o.sum(axis=1)\n",
    "    col_sums = o.sum(axis=0)\n",
    "    \n",
    "    expected = np.outer(row_sums, col_sums) / n\n",
    "    weight_matrix = np.outer(np.arange(o.shape[0]), np.arange(o.shape[0]))\n",
    "    weight_matrix = (weight_matrix - weight_matrix.T) ** 2 / (o.shape[0] - 1) ** 2\n",
    "    \n",
    "    kappa = 1 - (np.sum(weight_matrix * o) / np.sum(weight_matrix * expected))\n",
    "    return kappa\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Generate a confusion matrix for calculating QWK\n",
    "    \"\"\"\n",
    "    print(y_true)\n",
    "    print(y_pred)\n",
    "    max_rating = max(max(y_true), max(y_pred)) + 1\n",
    "    matrix = np.zeros((max_rating, max_rating))\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        matrix[t, p] += 1\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "print(\"Strat training\")\n",
    "losses = []\n",
    "mean_loss = 0\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        inputs, labels, mask = data\n",
    "        inputs = inputs.to(device)\n",
    "        mask = mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # inputs are in Size([2, 1, 512, 768]) but we need them in Size([2, 512, 768])\n",
    "        inputs = inputs.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, mask)\n",
    "        outputs_rounded = outputs.detach().round().long()\n",
    "        outputs_rounded = torch.clamp(outputs_rounded, min=0, max=6)\n",
    "        kappa = quadratic_weighted_kappa(labels.cpu().detach().numpy(), outputs_rounded.cpu().detach().numpy())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if len(losses) > 20:\n",
    "            mean_loss = np.mean(losses[-20:])\n",
    "        print(f\"Epoch {epoch + 1}, Batch {i + 1} loss: {loss.item()} mean : {mean_loss} kappa {kappa}\")\n",
    "\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orolol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
